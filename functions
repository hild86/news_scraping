library(rvest)
library(magrittr)
library(qdapDictionaries)
library(qdap)
library(wordcloud)
library(tm)
library(tidytext)
library(dplyr)

google_sentiment <- function(goomer, lang = "en", page="0") {

  url <- paste( "https://www.google.com/search?hl=", 
                lang, "&tbm=nws&tbas=0&authuser=0&q=", goomer,"&start=", page, sep="")

 
  headlines = read_html(url) %>%
    html_nodes(".r,.st") %>% 
    html_text()
 
  headlines.clean  <- headlines %>%
    # as.data.frame() %>%
    tolower() %>%
    removePunctuation() %>%
    removeNumbers() %>%
    stripWhitespace() %>%
    replace_contraction() %>%
    replace_abbreviation() %>%
    replace_symbol()
  
  frequency <- freq_terms(headlines.clean, top =10, at.least =1, stopwords=myStopWords)
  word.list <- word_list(headlines.clean)
  all <- left_join(word.list$fswl$all, pos.words.revised, by = c("WORD"="word"))

  plot(frequency)
  return(
    list("sentiment_index" = sum(all[which(all$sentiment == "positive"),]$FREQ) / 
           sum(all[which(all$sentiment == "negative"),]$FREQ), "frequency" = frequency))
  
}


bloom_sentiment <- function(bloomer) {

    url <- paste( "https://www.bloomberg.com/search?query=", bloomer,"&startTime=-1m", sep="")
    
    bloom <- read_html(url) %>%
      html_nodes("a") %>%
      html_attr('href')
    
    bloom.news <- bloom[grepl("https://www.bloomberg.com/news/" ,bloom)]
    bloom.politics <- bloom[grepl("https://www.bloomberg.com/politics/" ,bloom)]
    bloom.all <- append(bloom.news,bloom.politics) %>%
                    unique()
    bloom.all.refined_1 <- bloom.all[!grepl("special-reports", bloom.all)]
    bloom.all.refined <- bloom.all.refined_1[!grepl("features/", bloom.all.refined_1)]
    
    corpus.bloom.list <- list()
    try(
      
    for (item in 1:length(bloom.all.refined)) {
            link <- bloom.all.refined[item]
            corpus.bloom.list[[item]] <- read_html(link) %>%
                html_nodes("p") %>%
                      html_text()
    }
    )
    
    corpus.bloom <- unlist(corpus.bloom.list)
    
    corpus.bloom[!grepl("Connecting decision makers to a dynamic network",corpus.bloom)]
    
    corpus.bloom.clean  <- corpus.bloom %>%
      # as.data.frame() %>%
      tolower() %>%
      removePunctuation() %>%
      removeNumbers() %>%
      stripWhitespace() %>%
      replace_contraction() %>%
      replace_abbreviation() %>%
      replace_symbol()
    
    frequency <- freq_terms(corpus.bloom.clean, top =10, at.least =1, 
                            stopwords=myStopWords)
    word.list <- word_list(corpus.bloom.clean)
    all <- left_join(word.list$fswl$all, pos.words.revised, by = c("WORD"="word"))
    
    plot(frequency)
    return(
      list("sentiment_index" = sum(all[which(all$sentiment == "positive"),]$FREQ) / 
      sum(all[which(all$sentiment == "negative"),]$FREQ), "frequency" = frequency))
    
}


reut_sentiment <- function(reutoor) {

  url <- paste( "http://www.reuters.com/search/news?blob=", reutoor, sep="")
  
  reut <- read_html(url) %>%
    html_nodes("a") %>%
    html_attr('href')
  
  reut.news <- reut[grepl("/article/" ,reut)] %>%
    unique()
  
  reut.news.refined <- paste("http://www.reuters.com",reut.news, sep = "" )
  
  corpus.bloom.list <- list()

  try(  
  for (item in 1:length(reut.news.refined)) {
    link <- reut.news.refined[item]
    corpus.bloom.list[[item]] <- read_html(link) %>%
      html_nodes("p") %>%
      html_text()
  }
  )
  
  corpus.reut <- unlist(corpus.bloom.list)
  
  corpus.bloom.clean  <- corpus.reut %>%
    # as.data.frame() %>%
    tolower() %>%
    removePunctuation() %>%
    removeNumbers() %>%
    stripWhitespace() %>%
    replace_contraction() %>%
    replace_abbreviation() %>%
    replace_symbol()
  
  frequency <- freq_terms(corpus.bloom.clean, top =10, at.least =1, 
                          stopwords=myStopWords)
  word.list <- word_list(corpus.bloom.clean)
  all <- left_join(word.list$fswl$all, pos.words.revised, by = c("WORD"="word"))
  
  
  #  wordcloud(frequency$WORD, frequency$FREQ, colors=brewer.pal(8, "Dark2"))
  plot(frequency)
  return(
    list("sentiment_index" = sum(all[which(all$sentiment == "positive"),]$FREQ) / 
           sum(all[which(all$sentiment == "negative"),]$FREQ), "frequency" = frequency))
  
}
