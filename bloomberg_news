#'Bloomberg: note that even if you separate multiples words by "+" it doesn't always works

bloom_sentiment <- function(bloomer) {

    url <- paste( "https://www.bloomberg.com/search?query=", bloomer,"&startTime=-1m", sep="")
    
    bloom <- read_html(url) %>%
      html_nodes("a") %>%
      html_attr('href')
    
    bloom.news <- bloom[grepl("https://www.bloomberg.com/news/" ,bloom)]
    bloom.politics <- bloom[grepl("https://www.bloomberg.com/politics/" ,bloom)]
    bloom.all <- append(bloom.news,bloom.politics) %>%
                    unique()
    bloom.all.refined_1 <- bloom.all[!grepl("special-reports", bloom.all)]
    bloom.all.refined <- bloom.all.refined_1[!grepl("features/", bloom.all.refined_1)]
    
    corpus.bloom.list <- list()
    try(
      
    for (item in 1:length(bloom.all.refined)) {
            link <- bloom.all.refined[item]
            corpus.bloom.list[[item]] <- read_html(link) %>%
                html_nodes("p") %>%
                      html_text()
    }
    )
    
    corpus.bloom <- unlist(corpus.bloom.list)
    
    corpus.bloom[!grepl("Connecting decision makers to a dynamic network",corpus.bloom)]
    
    corpus.bloom.clean  <- corpus.bloom %>%
      # as.data.frame() %>%
      tolower() %>%
      removePunctuation() %>%
      removeNumbers() %>%
      stripWhitespace() %>%
      replace_contraction() %>%
      replace_abbreviation() %>%
      replace_symbol()
    
    frequency <- freq_terms(corpus.bloom.clean, top =10, at.least =1, 
                            stopwords=myStopWords)
    word.list <- word_list(corpus.bloom.clean)
    all <- left_join(word.list$fswl$all, pos.words.revised, by = c("WORD"="word"))
    
    plot(frequency)
    return(
      list("sentiment_index" = sum(all[which(all$sentiment == "positive"),]$FREQ) / 
      sum(all[which(all$sentiment == "negative"),]$FREQ), "frequency" = frequency))
    
}
